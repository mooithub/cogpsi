{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "source": [
    "# Week 3: Sequence models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 지금까지의 모델\n",
    "- 데이터와 라벨을 통해 규칙을 얻음\n",
    "![df](img/01.png)\n",
    "- 순서를 고려하지 않았기 때문에 일부 상황에 맞지 않음\n",
    "- 시계열 데이터를 예측하기 위해 순환 가능한 모델을 사용\n",
    "\n",
    "<img src=\"img/02.png\" width=\"50%\">\n",
    "\n",
    "<img src=\"img/03.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Networks(RNN)\n",
    "- 반복 가능한 신경망 모델을 만들자\n",
    "- 대략 이런 그림일까...?\n",
    "\n",
    "<img src=\"img/05.png\">\n",
    "\n",
    "- 풀어보면 이런 느낌\n",
    "\n",
    "<img src=\"img/06.png\" width=\"70%\">\n",
    "\n",
    "- RNN에 대해 자세히 알고싶으면 이 링크를 참조([Deep RNNs](https://www.coursera.org/lecture/nlp-sequence-models/deep-rnns-ehs0S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이걸로 뭘 할 수 있을까?\n",
    "- 시계열 데이터의 문맥을 이해할 수 있음\n",
    "\n",
    "<img src=\"img/07.png\" width=\"70%\">\n",
    "\n",
    "- 궁극적으로 이런걸 해보고자 함\n",
    "\n",
    "\n",
    "<img src=\"img/04.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### Long Short-Term Memory models(LSTM)\n",
    "- RNN은 시계열 데이터를 다루기 좋지만 Vanishing Gradient Problem 존재\n",
    "- 시퀀스가 길어지면 앞의 정보가 뒤로 충분히 전달되지 못하여 좋은 성능을 내기 어려움\n",
    "- 이를 해결하기 위해 고안된 기법이 LSTM\n",
    "- LSTM은 cell-state를 추가하여 gradient의 전파가 원활하게 되도록 도움\n",
    "\n",
    "<img src=\"img/08.png\" width=\"60%\">\n",
    "<img src=\"img/10.png\" width=\"60%\">\n",
    "\n",
    "- RNN의 내부 구조\n",
    "\n",
    "<img src=\"img/11.png\" width=\"40%\">\n",
    "\n",
    "- LSTM의 내부 구조\n",
    "\n",
    "<img src=\"img/12.png\" width=\"40%\">\n",
    "\n",
    "- LSTM에 대해 자세히 알고 싶으면, 다음 링크를 참조([LSTM](https://www.coursera.org/lecture/nlp-sequence-models/long-short-term-memory-lstm-KXoay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Recurrent Neural Network\n",
    "- 과거의 데이터 만으로 학습하는 것이 아닌, 미래의 데이터를 같이 학습\n",
    "- 하나의 출력을 위해 두개의 메모리 셀을 사용\n",
    "    - Forward States를 전달받아 현재 은닉상태를 계산\n",
    "    - Backward States를 전달받아 현재 은닉상태를 계산\n",
    "\n",
    "<img src=\"img/24.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 구현\n",
    "\n",
    "```python\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(tokenizer.vocab_size, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "```\n",
    "\n",
    "##### 모델 확인\n",
    "\n",
    "<img src=\"img/13.png\" width=\"70%\">\n",
    "\n",
    "### 다층 LSTM 구현\n",
    "\n",
    "```python\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(tokenizer.vocab_size, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "```\n",
    "\n",
    "##### 모델 확인\n",
    "\n",
    "<img src=\"img/14.png\" width=\"70%\">\n",
    "\n",
    "- LSTM의 `return_sequences=True`\n",
    "    - 다음 층으로 모든 은닉상태를 넘길 것인지에 대한 여부\n",
    "    \n",
    "    <img src=\"img/15.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능 비교\n",
    "\n",
    "- 10 Epochs\n",
    "\n",
    "<img src=\"img/16.png\">\n",
    "\n",
    "<img src=\"img/17.png\">\n",
    "\n",
    "- 50 epochs\n",
    "\n",
    "<img src=\"img/18.png\">\n",
    "\n",
    "<img src=\"img/19.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기존 모델 대비 성능 향상 확인\n",
    "- 기존 모델\n",
    "```python\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "```\n",
    "\n",
    "- LSTM 적용 모델\n",
    "\n",
    "```python\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "```\n",
    "- 성능 확인\n",
    "\n",
    "<img src=\"img/20.png\">\n",
    "\n",
    "<img src=\"img/21.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a convolutional network\n",
    "- RNN, LSTM의 계산비용 문제를 해결하기 위해 1D Conv사용\n",
    "- 시퀀스들의 지역 패턴을 인식\n",
    "- 윈도우를 지정하여 시퀀스의 오차를 수용하여 인식\n",
    "\n",
    "```python\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu')\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "```\n",
    "\n",
    "<img src=\"img/22.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 참고\n",
    "- [딥러닝을 이용한 자연어 처리 입문](https://wikidocs.net/book/2155)\n",
    "- [밑바닥부터 시작하는 딥러닝2](http://www.hanbit.co.kr/store/books/look.php?p_code=B8950212853)\n",
    "- [github code](https://github.com/lmoroney/dlaicourse/tree/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
